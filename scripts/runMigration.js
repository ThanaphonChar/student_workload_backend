import pg from 'pg';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import 'dotenv/config';

const { Pool } = pg;
const __dirname = path.dirname(fileURLToPath(import.meta.url));

// Configuration that works with local PostgreSQL
const poolConfig = process.env.DATABASE_URL
    ? {
        connectionString: process.env.DATABASE_URL,
        ssl: {
            rejectUnauthorized: false
        }
    }
    : {
        host: process.env.DB_HOST || 'localhost',
        port: process.env.DB_PORT || 5432,
        database: process.env.DB_NAME,
        user: process.env.DB_USER,
        password: process.env.DB_PASSWORD,
        ssl: false // No SSL for local development
    };

const pool = new Pool(poolConfig);

async function runMigration() {
  const client = await pool.connect();
  
  try {
    console.log('ðŸ”„ Reading migration file...');
    const migrationPath = path.join(__dirname, '..', 'migrations', '001_create_academic_terms.sql');
    const migrationSQL = fs.readFileSync(migrationPath, 'utf8');
    
    console.log('ðŸ”„ Executing migration...');
    await client.query(migrationSQL);
    
    console.log('âœ… Migration completed successfully!');
    console.log('\nTables created:');
    console.log('  - academic_terms');
    console.log('  - term_subjects');
    console.log('  - term_subject_lecturers');
    
  } catch (error) {
    console.error('âŒ Migration failed:', error.message);
    if (error.message.includes('already exists')) {
      console.log('\nâš ï¸  Tables may already exist. This is okay if running migration again.');
    }
    throw error;
  } finally {
    client.release();
    await pool.end();
  }
}

runMigration().catch(err => {
  console.error('Fatal error:', err);
  process.exit(1);
});
